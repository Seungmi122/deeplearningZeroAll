{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "tf.enable_eager_execution()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    train_data = np.expand_dims(train_data, axis = -1) #add channel\n",
    "    test_data = np.expand_dims(test_data, axis = -1)\n",
    "    \n",
    "    train_data, test_data = normalize(train_data, test_data)\n",
    "    \n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "    \n",
    "def normalize(train_data, test_data):\n",
    "    train_data = train_data.astype(np.float32)/255.0\n",
    "    test_data = test_data.astype(np.float32)/255.0\n",
    "    return train_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training = True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels = labels))\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training = False)\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten():\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init):\n",
    "    return tf.keras.layers.Dense(units = label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu():\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model, self).__init__()\n",
    "        weight_init = tf.keras.initializers.RandomNormal()\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten()) #why? fully connected layer사용할거라\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.model.add(dense(256, weight_init)) #[N,256]\n",
    "            self.model.add(relu())\n",
    "            \n",
    "        self.model.add(dense(label_dim, weight_init)) #[N,10]\n",
    "        \n",
    "    def call(self, x, training = None, mask = None):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_mnist()\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "training_epochs = 1\n",
    "training_iterations = len(train_x)//batch_size\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_flag = True\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
    "                    shuffle(buffer_size=100000).\\\n",
    "                    prefetch(buffer_size=batch_size).\\\n",
    "                    batch(batch_size).\\\n",
    "                    repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
    "                    shuffle(buffer_size=100000).\\\n",
    "                    prefetch(buffer_size=len(test_x)).\\\n",
    "                    batch(len(test_x)).\\\n",
    "                    repeat()\n",
    "\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "test_iterator = test_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = create_model(label_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits = True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [    0/  468], train_loss: 2.17042923, train_accuracy: 0.2656, test_Accuracy: 0.1997\n",
      "Epoch: [ 0] [    1/  468], train_loss: 2.08910751, train_accuracy: 0.4297, test_Accuracy: 0.2865\n",
      "Epoch: [ 0] [    2/  468], train_loss: 2.01778126, train_accuracy: 0.3750, test_Accuracy: 0.3583\n",
      "Epoch: [ 0] [    3/  468], train_loss: 1.96049321, train_accuracy: 0.5078, test_Accuracy: 0.4242\n",
      "Epoch: [ 0] [    4/  468], train_loss: 1.84629560, train_accuracy: 0.6172, test_Accuracy: 0.4799\n",
      "Epoch: [ 0] [    5/  468], train_loss: 1.84598053, train_accuracy: 0.5547, test_Accuracy: 0.5492\n",
      "Epoch: [ 0] [    6/  468], train_loss: 1.74395049, train_accuracy: 0.6328, test_Accuracy: 0.6004\n",
      "Epoch: [ 0] [    7/  468], train_loss: 1.62881565, train_accuracy: 0.6797, test_Accuracy: 0.6385\n",
      "Epoch: [ 0] [    8/  468], train_loss: 1.51331866, train_accuracy: 0.7266, test_Accuracy: 0.6716\n",
      "Epoch: [ 0] [    9/  468], train_loss: 1.43385494, train_accuracy: 0.7109, test_Accuracy: 0.7002\n",
      "Epoch: [ 0] [   10/  468], train_loss: 1.31595159, train_accuracy: 0.7578, test_Accuracy: 0.7158\n",
      "Epoch: [ 0] [   11/  468], train_loss: 1.27265215, train_accuracy: 0.7578, test_Accuracy: 0.7243\n",
      "Epoch: [ 0] [   12/  468], train_loss: 1.11342549, train_accuracy: 0.7812, test_Accuracy: 0.7360\n",
      "Epoch: [ 0] [   13/  468], train_loss: 1.12271285, train_accuracy: 0.7266, test_Accuracy: 0.7462\n",
      "Epoch: [ 0] [   14/  468], train_loss: 0.94673949, train_accuracy: 0.7031, test_Accuracy: 0.7632\n",
      "Epoch: [ 0] [   15/  468], train_loss: 0.91846734, train_accuracy: 0.8125, test_Accuracy: 0.7896\n",
      "Epoch: [ 0] [   16/  468], train_loss: 0.93419081, train_accuracy: 0.7656, test_Accuracy: 0.8125\n",
      "Epoch: [ 0] [   17/  468], train_loss: 0.74040163, train_accuracy: 0.8281, test_Accuracy: 0.8291\n",
      "Epoch: [ 0] [   18/  468], train_loss: 0.72984421, train_accuracy: 0.8438, test_Accuracy: 0.8268\n",
      "Epoch: [ 0] [   19/  468], train_loss: 0.76307929, train_accuracy: 0.8125, test_Accuracy: 0.8241\n",
      "Epoch: [ 0] [   20/  468], train_loss: 0.65481055, train_accuracy: 0.8281, test_Accuracy: 0.8242\n",
      "Epoch: [ 0] [   21/  468], train_loss: 0.57784522, train_accuracy: 0.8359, test_Accuracy: 0.8265\n",
      "Epoch: [ 0] [   22/  468], train_loss: 0.72566617, train_accuracy: 0.7578, test_Accuracy: 0.8361\n",
      "Epoch: [ 0] [   23/  468], train_loss: 0.53848243, train_accuracy: 0.8438, test_Accuracy: 0.8386\n",
      "Epoch: [ 0] [   24/  468], train_loss: 0.48972923, train_accuracy: 0.8594, test_Accuracy: 0.8362\n",
      "Epoch: [ 0] [   25/  468], train_loss: 0.47024220, train_accuracy: 0.8438, test_Accuracy: 0.8385\n",
      "Epoch: [ 0] [   26/  468], train_loss: 0.59739578, train_accuracy: 0.8281, test_Accuracy: 0.8461\n",
      "Epoch: [ 0] [   27/  468], train_loss: 0.44741005, train_accuracy: 0.9141, test_Accuracy: 0.8372\n",
      "Epoch: [ 0] [   28/  468], train_loss: 0.50349379, train_accuracy: 0.8438, test_Accuracy: 0.8377\n",
      "Epoch: [ 0] [   29/  468], train_loss: 0.50814497, train_accuracy: 0.8359, test_Accuracy: 0.8572\n",
      "Epoch: [ 0] [   30/  468], train_loss: 0.50317210, train_accuracy: 0.8594, test_Accuracy: 0.8720\n",
      "Epoch: [ 0] [   31/  468], train_loss: 0.52658486, train_accuracy: 0.8125, test_Accuracy: 0.8709\n",
      "Epoch: [ 0] [   32/  468], train_loss: 0.34125233, train_accuracy: 0.8906, test_Accuracy: 0.8570\n",
      "Epoch: [ 0] [   33/  468], train_loss: 0.41651893, train_accuracy: 0.8594, test_Accuracy: 0.8407\n",
      "Epoch: [ 0] [   34/  468], train_loss: 0.46694607, train_accuracy: 0.8828, test_Accuracy: 0.8453\n",
      "Epoch: [ 0] [   35/  468], train_loss: 0.44142821, train_accuracy: 0.8594, test_Accuracy: 0.8617\n",
      "Epoch: [ 0] [   36/  468], train_loss: 0.39298749, train_accuracy: 0.9062, test_Accuracy: 0.8821\n",
      "Epoch: [ 0] [   37/  468], train_loss: 0.37030727, train_accuracy: 0.8984, test_Accuracy: 0.8826\n",
      "Epoch: [ 0] [   38/  468], train_loss: 0.46540046, train_accuracy: 0.8359, test_Accuracy: 0.8750\n",
      "Epoch: [ 0] [   39/  468], train_loss: 0.42987013, train_accuracy: 0.8750, test_Accuracy: 0.8647\n",
      "Epoch: [ 0] [   40/  468], train_loss: 0.54646498, train_accuracy: 0.8203, test_Accuracy: 0.8708\n",
      "Epoch: [ 0] [   41/  468], train_loss: 0.42559052, train_accuracy: 0.8828, test_Accuracy: 0.8810\n",
      "Epoch: [ 0] [   42/  468], train_loss: 0.42400515, train_accuracy: 0.8516, test_Accuracy: 0.8792\n",
      "Epoch: [ 0] [   43/  468], train_loss: 0.34254000, train_accuracy: 0.8750, test_Accuracy: 0.8711\n",
      "Epoch: [ 0] [   44/  468], train_loss: 0.43177330, train_accuracy: 0.8750, test_Accuracy: 0.8768\n",
      "Epoch: [ 0] [   45/  468], train_loss: 0.34801507, train_accuracy: 0.9219, test_Accuracy: 0.8787\n",
      "Epoch: [ 0] [   46/  468], train_loss: 0.41221195, train_accuracy: 0.8594, test_Accuracy: 0.8874\n",
      "Epoch: [ 0] [   47/  468], train_loss: 0.31048879, train_accuracy: 0.9219, test_Accuracy: 0.8839\n",
      "Epoch: [ 0] [   48/  468], train_loss: 0.47240970, train_accuracy: 0.8516, test_Accuracy: 0.8790\n",
      "Epoch: [ 0] [   49/  468], train_loss: 0.39334625, train_accuracy: 0.8672, test_Accuracy: 0.8745\n",
      "Epoch: [ 0] [   50/  468], train_loss: 0.37129831, train_accuracy: 0.9219, test_Accuracy: 0.8789\n",
      "Epoch: [ 0] [   51/  468], train_loss: 0.46430099, train_accuracy: 0.8594, test_Accuracy: 0.8884\n",
      "Epoch: [ 0] [   52/  468], train_loss: 0.32014877, train_accuracy: 0.8906, test_Accuracy: 0.8943\n",
      "Epoch: [ 0] [   53/  468], train_loss: 0.37881207, train_accuracy: 0.9141, test_Accuracy: 0.8955\n",
      "Epoch: [ 0] [   54/  468], train_loss: 0.32498759, train_accuracy: 0.9141, test_Accuracy: 0.8928\n",
      "Epoch: [ 0] [   55/  468], train_loss: 0.36702478, train_accuracy: 0.9062, test_Accuracy: 0.8925\n",
      "Epoch: [ 0] [   56/  468], train_loss: 0.33170161, train_accuracy: 0.8828, test_Accuracy: 0.8969\n",
      "Epoch: [ 0] [   57/  468], train_loss: 0.32702732, train_accuracy: 0.8984, test_Accuracy: 0.9010\n",
      "Epoch: [ 0] [   58/  468], train_loss: 0.36270937, train_accuracy: 0.8906, test_Accuracy: 0.9042\n",
      "Epoch: [ 0] [   59/  468], train_loss: 0.33641404, train_accuracy: 0.8750, test_Accuracy: 0.9035\n",
      "Epoch: [ 0] [   60/  468], train_loss: 0.25332966, train_accuracy: 0.9375, test_Accuracy: 0.8993\n",
      "Epoch: [ 0] [   61/  468], train_loss: 0.47684196, train_accuracy: 0.8594, test_Accuracy: 0.8926\n",
      "Epoch: [ 0] [   62/  468], train_loss: 0.41403329, train_accuracy: 0.8828, test_Accuracy: 0.8933\n",
      "Epoch: [ 0] [   63/  468], train_loss: 0.31756717, train_accuracy: 0.8984, test_Accuracy: 0.8956\n",
      "Epoch: [ 0] [   64/  468], train_loss: 0.40653095, train_accuracy: 0.8750, test_Accuracy: 0.9008\n",
      "Epoch: [ 0] [   65/  468], train_loss: 0.44958070, train_accuracy: 0.8672, test_Accuracy: 0.9035\n",
      "Epoch: [ 0] [   66/  468], train_loss: 0.39746785, train_accuracy: 0.8906, test_Accuracy: 0.9052\n",
      "Epoch: [ 0] [   67/  468], train_loss: 0.41178918, train_accuracy: 0.8828, test_Accuracy: 0.9046\n",
      "Epoch: [ 0] [   68/  468], train_loss: 0.41155320, train_accuracy: 0.9141, test_Accuracy: 0.9042\n",
      "Epoch: [ 0] [   69/  468], train_loss: 0.33971286, train_accuracy: 0.9062, test_Accuracy: 0.9051\n",
      "Epoch: [ 0] [   70/  468], train_loss: 0.33661306, train_accuracy: 0.8984, test_Accuracy: 0.9054\n",
      "Epoch: [ 0] [   71/  468], train_loss: 0.30276525, train_accuracy: 0.9141, test_Accuracy: 0.9065\n",
      "Epoch: [ 0] [   72/  468], train_loss: 0.42215508, train_accuracy: 0.8828, test_Accuracy: 0.9074\n",
      "Epoch: [ 0] [   73/  468], train_loss: 0.22362792, train_accuracy: 0.9219, test_Accuracy: 0.9078\n",
      "Epoch: [ 0] [   74/  468], train_loss: 0.35760731, train_accuracy: 0.9219, test_Accuracy: 0.9068\n",
      "Epoch: [ 0] [   75/  468], train_loss: 0.34985888, train_accuracy: 0.8984, test_Accuracy: 0.9060\n",
      "Epoch: [ 0] [   76/  468], train_loss: 0.28246877, train_accuracy: 0.9297, test_Accuracy: 0.9062\n",
      "Epoch: [ 0] [   77/  468], train_loss: 0.31677201, train_accuracy: 0.9375, test_Accuracy: 0.9085\n",
      "Epoch: [ 0] [   78/  468], train_loss: 0.27603573, train_accuracy: 0.9219, test_Accuracy: 0.9095\n",
      "Epoch: [ 0] [   79/  468], train_loss: 0.39483440, train_accuracy: 0.9141, test_Accuracy: 0.9081\n",
      "Epoch: [ 0] [   80/  468], train_loss: 0.24447237, train_accuracy: 0.9141, test_Accuracy: 0.9086\n",
      "Epoch: [ 0] [   81/  468], train_loss: 0.19971943, train_accuracy: 0.9453, test_Accuracy: 0.9070\n",
      "Epoch: [ 0] [   82/  468], train_loss: 0.25477523, train_accuracy: 0.8906, test_Accuracy: 0.9060\n",
      "Epoch: [ 0] [   83/  468], train_loss: 0.37825018, train_accuracy: 0.8984, test_Accuracy: 0.9062\n",
      "Epoch: [ 0] [   84/  468], train_loss: 0.32280549, train_accuracy: 0.9141, test_Accuracy: 0.9095\n",
      "Epoch: [ 0] [   85/  468], train_loss: 0.20751268, train_accuracy: 0.9141, test_Accuracy: 0.9088\n",
      "Epoch: [ 0] [   86/  468], train_loss: 0.26615736, train_accuracy: 0.9297, test_Accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   87/  468], train_loss: 0.41007906, train_accuracy: 0.8906, test_Accuracy: 0.9053\n",
      "Epoch: [ 0] [   88/  468], train_loss: 0.34035683, train_accuracy: 0.8984, test_Accuracy: 0.9020\n",
      "Epoch: [ 0] [   89/  468], train_loss: 0.45941332, train_accuracy: 0.8516, test_Accuracy: 0.9063\n",
      "Epoch: [ 0] [   90/  468], train_loss: 0.32666248, train_accuracy: 0.8984, test_Accuracy: 0.9075\n",
      "Epoch: [ 0] [   91/  468], train_loss: 0.30755290, train_accuracy: 0.9297, test_Accuracy: 0.9036\n",
      "Epoch: [ 0] [   92/  468], train_loss: 0.36861593, train_accuracy: 0.8906, test_Accuracy: 0.9028\n",
      "Epoch: [ 0] [   93/  468], train_loss: 0.50677133, train_accuracy: 0.8594, test_Accuracy: 0.9050\n",
      "Epoch: [ 0] [   94/  468], train_loss: 0.51624763, train_accuracy: 0.8281, test_Accuracy: 0.9117\n",
      "Epoch: [ 0] [   95/  468], train_loss: 0.26408342, train_accuracy: 0.9297, test_Accuracy: 0.9143\n",
      "Epoch: [ 0] [   96/  468], train_loss: 0.18952349, train_accuracy: 0.9453, test_Accuracy: 0.9118\n",
      "Epoch: [ 0] [   97/  468], train_loss: 0.28313962, train_accuracy: 0.9141, test_Accuracy: 0.9088\n",
      "Epoch: [ 0] [   98/  468], train_loss: 0.23587120, train_accuracy: 0.9141, test_Accuracy: 0.9073\n",
      "Epoch: [ 0] [   99/  468], train_loss: 0.19216125, train_accuracy: 0.9453, test_Accuracy: 0.9049\n",
      "Epoch: [ 0] [  100/  468], train_loss: 0.19748525, train_accuracy: 0.9141, test_Accuracy: 0.9052\n",
      "Epoch: [ 0] [  101/  468], train_loss: 0.22222880, train_accuracy: 0.9141, test_Accuracy: 0.9096\n",
      "Epoch: [ 0] [  102/  468], train_loss: 0.22691101, train_accuracy: 0.9219, test_Accuracy: 0.9119\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2465a2901eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \"\"\"\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_saveables_for_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2104\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prevent networks from losing connects or trained info\n",
    "checkpoint = tf.train.Checkpoint(dnn=network)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for idx in range(training_iterations):\n",
    "        train_input, train_label = train_iterator.get_next()\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = network(train_input)\n",
    "#            loss = loss_object(predictions, train_label)     # 위의 설명 2. 를 참고하여 None을 채우세요.\n",
    "            loss = loss_fn(network, train_input, train_label)\n",
    "        grads = tape.gradient(loss, network.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars = zip(grads, network.variables))\n",
    "        \n",
    "        train_loss = loss_fn(network, train_input, train_label)\n",
    "        train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "        \n",
    "        test_input, test_label = test_iterator.get_next()\n",
    "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "        \n",
    "        print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\"\\\n",
    "             % (epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_Accuracy: %.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
